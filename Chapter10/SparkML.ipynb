{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Y07VsvZNpS",
        "outputId": "9683eec3-9839-4f96-98a3-09edb8718827"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=4a7051fabf6c2f3771642cbe99870d1e75bdff4c338b2ab7f8ba1de288545140\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\n",
        "!unzip AirQualityUCI.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfZiGdpiZY47",
        "outputId": "de735041-7c0b-441c-dd93-50bfb1dae1df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-19 06:29:51--  https://archive.ics.uci.edu/ml/machine-learning-databases/00360/AirQualityUCI.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘AirQualityUCI.zip’\n",
            "\n",
            "AirQualityUCI.zip       [   <=>              ]   1.47M  3.21MB/s    in 0.5s    \n",
            "\n",
            "2024-10-19 06:29:52 (3.21 MB/s) - ‘AirQualityUCI.zip’ saved [1543989]\n",
            "\n",
            "Archive:  AirQualityUCI.zip\n",
            "  inflating: AirQualityUCI.csv       \n",
            "  inflating: AirQualityUCI.xlsx      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import lag, col\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import DecisionTreeRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "5fkla1FbgBMa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"TimeSeriesAnalysis\").getOrCreate()\n",
        "\n",
        "# Load the dataset into Pandas first for quick inspection\n",
        "df_pandas = pd.read_csv('AirQualityUCI.csv', sep=';', decimal=',', parse_dates=[['Date', 'Time']])\n",
        "\n",
        "# Preview the dataset\n",
        "df_pandas.head()\n",
        "\n",
        "# Remove unnecessary columns and fix the data types\n",
        "df_pandas = df_pandas[['Date_Time', 'CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)']]\n",
        "df_pandas = df_pandas.dropna()\n",
        "# Replace negative values with NaN\n",
        "df_pandas['CO(GT)'] = df_pandas['CO(GT)'].apply(lambda x: np.nan if x < 0 else x)\n",
        "\n",
        "# You can then apply interpolation to fill missing values\n",
        "df_pandas['CO(GT)'] = df_pandas['CO(GT)'].interpolate()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH4n38DIZo2J",
        "outputId": "94a7aa3d-8f0a-4659-a4ec-2c8314ddd104"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-a340626d5bfc>:5: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
            "  df_pandas = pd.read_csv('AirQualityUCI.csv', sep=';', decimal=',', parse_dates=[['Date', 'Time']])\n",
            "<ipython-input-7-a340626d5bfc>:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_pandas = pd.read_csv('AirQualityUCI.csv', sep=';', decimal=',', parse_dates=[['Date', 'Time']])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns to replace dots with underscores\n",
        "df_pandas.columns = [col.replace('.', '_') for col in df_pandas.columns]\n",
        "\n",
        "# Convert to Spark DataFrame\n",
        "data = spark.createDataFrame(df_pandas)\n",
        "\n",
        "# Show the renamed columns\n",
        "data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5X4RGX1aWko",
        "outputId": "e9e63a83-c9b8-44f0-e222-819b30f8182d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+\n",
            "|          Date_Time|CO(GT)|PT08_S1(CO)|NMHC(GT)|C6H6(GT)|PT08_S2(NMHC)|NOx(GT)|PT08_S3(NOx)|\n",
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+\n",
            "|10/03/2004 18.00.00|   2.6|     1360.0|   150.0|    11.9|       1046.0|  166.0|      1056.0|\n",
            "|10/03/2004 19.00.00|   2.0|     1292.0|   112.0|     9.4|        955.0|  103.0|      1174.0|\n",
            "|10/03/2004 20.00.00|   2.2|     1402.0|    88.0|     9.0|        939.0|  131.0|      1140.0|\n",
            "|10/03/2004 21.00.00|   2.2|     1376.0|    80.0|     9.2|        948.0|  172.0|      1092.0|\n",
            "|10/03/2004 22.00.00|   1.6|     1272.0|    51.0|     6.5|        836.0|  131.0|      1205.0|\n",
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a window specification for lagging the time series data\n",
        "window = Window.orderBy(\"Date_Time\")\n",
        "\n",
        "# Generate lag features using backticks around column names with special characters\n",
        "data_with_lags = data.withColumn(\"lag_1\", lag(col(\"`CO(GT)`\"), 1).over(window)) \\\n",
        "                     .withColumn(\"lag_2\", lag(col(\"`CO(GT)`\"), 2).over(window)) \\\n",
        "                     .withColumn(\"lag_3\", lag(col(\"`CO(GT)`\"), 3).over(window)) \\\n",
        "                     .withColumn(\"lag_4\", lag(col(\"`CO(GT)`\"), 4).over(window)) \\\n",
        "                     .withColumn(\"lag_5\", lag(col(\"`CO(GT)`\"), 5).over(window))\n",
        "\n",
        "# Drop rows with missing lag values\n",
        "data_clean = data_with_lags.dropna()\n",
        "\n",
        "# Show the cleaned data with lag features\n",
        "data_clean.show(5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkcfqXwXZ5cg",
        "outputId": "387002fe-3314-490f-ea46-75e9d2f59a8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+-----+-----+-----+-----+-----------------+\n",
            "|          Date_Time|CO(GT)|PT08_S1(CO)|NMHC(GT)|C6H6(GT)|PT08_S2(NMHC)|NOx(GT)|PT08_S3(NOx)|lag_1|lag_2|lag_3|lag_4|            lag_5|\n",
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+-----+-----+-----+-----+-----------------+\n",
            "|01/01/2005 05.00.00|   1.4|     1004.0|  -200.0|     4.8|        753.0|  181.0|       879.0|  1.9|  2.7|  2.5|  1.6|1.595876288659794|\n",
            "|01/01/2005 06.00.00|   1.5|     1001.0|  -200.0|     5.3|        777.0|  171.0|       859.0|  1.4|  1.9|  2.7|  2.5|              1.6|\n",
            "|01/01/2005 07.00.00|   1.4|      974.0|  -200.0|     4.5|        736.0|  168.0|       888.0|  1.5|  1.4|  1.9|  2.7|              2.5|\n",
            "|01/01/2005 08.00.00|   1.1|      915.0|  -200.0|     3.0|        653.0|  169.0|       973.0|  1.4|  1.5|  1.4|  1.9|              2.7|\n",
            "|01/01/2005 09.00.00|   1.0|      939.0|  -200.0|     3.0|        649.0|  145.0|       996.0|  1.1|  1.4|  1.5|  1.4|              1.9|\n",
            "+-------------------+------+-----------+--------+--------+-------------+-------+------------+-----+-----+-----+-----+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assemble the features for scaling\n",
        "assembler = VectorAssembler(inputCols=[\"lag_1\", \"lag_2\", \"lag_3\", \"lag_4\", \"lag_5\"], outputCol=\"features\")\n",
        "\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "training_data = assembler.transform(data_clean)\n",
        "scaler_model = scaler.fit(training_data)\n",
        "scaled_data = scaler_model.transform(training_data)\n"
      ],
      "metadata": {
        "id": "CaLmoms7cciP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Tree Regressor model\n",
        "dt = DecisionTreeRegressor(featuresCol=\"scaled_features\", labelCol=\"CO(GT)\")\n",
        "\n",
        "# Train the model\n",
        "dt_model = dt.fit(scaled_data)\n",
        "\n",
        "# Make predictions\n",
        "predictions = dt_model.transform(scaled_data)\n",
        "\n",
        "# Show predictions\n",
        "predictions.select(\"Date_Time\", \"`CO(GT)`\", \"prediction\").show(5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es2LegoCce4y",
        "outputId": "27c7771a-738d-44e7-9d38-4470db08e255"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+------+------------------+\n",
            "|          Date_Time|CO(GT)|        prediction|\n",
            "+-------------------+------+------------------+\n",
            "|01/01/2005 05.00.00|   1.4| 1.908670011325342|\n",
            "|01/01/2005 06.00.00|   1.5|1.5199851487067881|\n",
            "|01/01/2005 07.00.00|   1.4|1.5199851487067881|\n",
            "|01/01/2005 08.00.00|   1.1|1.5199851487067881|\n",
            "|01/01/2005 09.00.00|   1.0| 1.179554701734488|\n",
            "+-------------------+------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the evaluator\n",
        "evaluator = RegressionEvaluator(labelCol=\"CO(GT)\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "# Compute RMSE (Root Mean Squared Error)\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRaR_vF7ardQ",
        "outputId": "41425226-39b2-4384-e9e2-240c1810fb1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.7121596162653802\n"
          ]
        }
      ]
    }
  ]
}