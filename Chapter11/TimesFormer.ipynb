{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkpIrcJYy3Rs",
        "outputId": "61df43ae-e8d5-4519-9b63-10402027ba9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting av\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-14.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Educat8n/images/raw/refs/heads/main/dogs.mp4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8LpRnRL5MBI",
        "outputId": "b2ea8766-de87-4adc-9882-b982589e4606"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-08 10:31:10--  https://github.com/Educat8n/images/raw/refs/heads/main/dogs.mp4\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Educat8n/images/refs/heads/main/dogs.mp4 [following]\n",
            "--2025-04-08 10:31:10--  https://raw.githubusercontent.com/Educat8n/images/refs/heads/main/dogs.mp4\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4913572 (4.7M) [application/octet-stream]\n",
            "Saving to: ‘dogs.mp4’\n",
            "\n",
            "dogs.mp4            100%[===================>]   4.69M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2025-04-08 10:31:11 (54.1 MB/s) - ‘dogs.mp4’ saved [4913572/4913572]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TimesformerForVideoClassification, AutoImageProcessor\n",
        "from torchvision.io import read_video\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToPILImage\n",
        "import torch\n",
        "\n",
        "# Load model and processor\n",
        "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "\n",
        "# Load video (fix timestamp warning)\n",
        "video_path = \"dogs.mp4\"\n",
        "video, _, _ = read_video(video_path, pts_unit='sec')\n",
        "\n",
        "# Use first 8 frames\n",
        "frames = video[:8]  # shape: [T, H, W, C]\n",
        "\n",
        "# Define transform: convert to PIL (let processor handle scaling)\n",
        "transform = Compose([\n",
        "    Resize(256),\n",
        "    CenterCrop(224),\n",
        "    ToPILImage()\n",
        "])\n",
        "\n",
        "# Transform each frame to PIL\n",
        "processed_frames = [transform(frame.permute(2, 0, 1)) for frame in frames]\n",
        "\n",
        "# Pass through processor\n",
        "inputs = processor(images=processed_frames, return_tensors=\"pt\", do_rescale=False)\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Print top prediction\n",
        "pred_class = outputs.logits.argmax(-1).item()\n",
        "print(\"Predicted action:\", model.config.id2label[pred_class])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e65Q0vUnzwuf",
        "outputId": "2f7481ec-b1d5-43fa-b32d-d71823a8a793"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted action: carrying baby\n"
          ]
        }
      ]
    }
  ]
}